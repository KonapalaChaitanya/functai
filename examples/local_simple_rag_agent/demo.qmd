
```{python}
from attachments import Attachments, set_verbose
set_verbose(False)

from ovllm import llm, llmtogpu
from functai import ai

llmtogpu("Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
        max_tokens=500, 
vllm_args={"tensor_parallel_size": 2, "gpu_memory_utilization": 0.80,
"max_model_len": 12000})

rag("What castle David Gregory inherited? Look there:" +
    "Always call doubleck tool at least once!" +
    "https://en.wikipedia.org/wiki/David_Gregory_(physician)")
```

```{python}
def website_retriever(url):
    "Retrieves text content of a url"
    return Attachments(url + "[images: false]").text

```

```{python}
@ai(lm=llm, tools=[website_retriever, doublecheck])
def rag(question) -> str:
    ...
```

```{python}
@ai(lm=llm, module="cot")
def doublecheck(fact: str, grounding: str) -> bool:
    """Provided a fact and the grounding (a short snippet) 
    where that fact originates this function returns True 
    is the fact is correctly extracted
    """
    ...

```


```{python}
from functai import ai, configure
configure(lm =llm)
```


```{python}
@ai
def rag(question, context):
    reasoning = _ai
    answer = _ai
    return answer

rag("What's the name of the castle that David Gregory inherited?", ctx)
```


```{python}
def website_retriever(url):
    "Retrieves text content of a url"
    return Attachments(url + "[images: false]").text

@ai
def rag(question):
    answer = _ai
    return answer

rag(
    "What's the name of the castle that David Gregory inherited?" +
    "the answer is in that page https://en.wikipedia.org/wiki/David_Gregory_(physician)")
```



